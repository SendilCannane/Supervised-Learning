{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.12 0.24 0.36 0.48 0.6  0.72 0.84 0.96 1.08 1.2  1.32 1.44 1.56\n",
      " 1.68 1.8  1.92 2.04 2.16 2.28 2.4  2.52 2.64 2.76 2.88 3.   3.12 3.24\n",
      " 3.36 3.48 3.6  3.72 3.84 3.96 4.08 4.2  4.32 4.44 4.56 4.68 4.8  4.92\n",
      " 5.04 5.16 5.28 5.4  5.52 5.64 5.76 5.88 6.   6.12 6.24 6.36 6.48 6.6\n",
      " 6.72 6.84 6.96 7.08 7.2  7.32 7.44 7.56 7.68 7.8  7.92 8.04 8.16 8.28\n",
      " 8.4  8.52 8.64 8.76 8.88 9.   9.12 9.24 9.36 9.48 9.6  9.72 9.84 9.96]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.arange(0.0,10.02,0.12)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyper-parameter\n",
    "learning_rate = 0.03\n",
    "training_epochs = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.3    4.4    5.5    6.71   6.93   4.168  9.779  6.182  7.59   2.167\n",
      "  7.042 10.791  5.313  7.997  5.654  9.27   3.1  ]\n",
      "3.3\n",
      "4.4\n",
      "5.5\n",
      "6.71\n",
      "6.93\n",
      "4.168\n",
      "9.779\n",
      "6.182\n",
      "7.59\n",
      "2.167\n",
      "7.042\n",
      "10.791\n",
      "5.313\n",
      "7.997\n",
      "5.654\n",
      "9.27\n",
      "3.1\n"
     ]
    }
   ],
   "source": [
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "print (train_X)\n",
    "n_samples = train_X.shape[0]   # 17 - it's nothing but a length\n",
    "#for i in range(train_X.shape[0]):\n",
    " #   print (train_X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(10.791, 3.465), (4.168, 1.573), (5.313, 1.65), (7.997, 2.904), (9.27, 2.94), (6.93, 1.694), (3.3, 1.7), (9.779, 3.366), (5.654, 2.42), (2.167, 1.221), (3.1, 1.3), (6.71, 3.19), (6.182, 2.596), (4.4, 2.76), (7.042, 2.827), (5.5, 2.09), (7.59, 2.53)}\n"
     ]
    }
   ],
   "source": [
    "z = zip(train_X, train_Y)\n",
    "train_data = set(z)\n",
    "print (train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight : <tf.Variable 'weight_1:0' shape=() dtype=float32_ref> \n",
      " Bias :<tf.Variable 'bias_1:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "W = tf.Variable(rng.randn(), name = \"weight\")\n",
    "b = tf.Variable(rng.randn(), name = \"bias\")\n",
    "print(\"Weight : %s\" %W, \"\\n Bias :%s\" %b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = tf.add(tf.multiply(X,W),b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "#cost = (1/n) * sum ([val**2 for val in (y-y_predicted)])\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      ds = ds.shuffle(10000)\n",
    "    \n",
    "    # Return the next batch of data.\n",
    "    features, labels = ds.make_one_shot_iterator().get_next()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate:  0.03\n",
      "Epoch : 0050 Cost :  0.165876836 Weight : 0.40712887 Bias :  -0.38274065\n",
      "Epoch : 0100 Cost :  0.138285682 Weight : 0.37959653 Bias :  -0.17980567\n",
      "Epoch : 0150 Cost :  0.119306371 Weight : 0.35676453 Bias :  -0.01151639\n",
      "Epoch : 0200 Cost :  0.106250159 Weight : 0.33783048 Bias :  0.12804215\n",
      "Epoch : 0250 Cost :  0.097267993 Weight : 0.3221289 Bias :  0.24377495\n",
      "Epoch : 0300 Cost :  0.091088131 Weight : 0.3091079 Bias :  0.33974966\n",
      "Epoch : 0350 Cost :  0.086835951 Weight : 0.29830983 Bias :  0.41933933\n",
      "Epoch : 0400 Cost :  0.083909728 Weight : 0.2893553 Bias :  0.4853414\n",
      "Epoch : 0450 Cost :  0.081895761 Weight : 0.2819294 Bias :  0.5400761\n",
      "Epoch : 0500 Cost :  0.080509461 Weight : 0.27577135 Bias :  0.58546543\n",
      "Epoch : 0550 Cost :  0.079554982 Weight : 0.27066457 Bias :  0.6231063\n",
      "Epoch : 0600 Cost :  0.078897662 Weight : 0.26642972 Bias :  0.65432066\n",
      "Epoch : 0650 Cost :  0.078444891 Weight : 0.26291776 Bias :  0.68020636\n",
      "Epoch : 0700 Cost :  0.078132905 Weight : 0.2600054 Bias :  0.70167243\n",
      "Epoch : 0750 Cost :  0.077917799 Weight : 0.2575902 Bias :  0.71947443\n",
      "Epoch : 0800 Cost :  0.077769443 Weight : 0.2555874 Bias :  0.7342367\n",
      "Epoch : 0850 Cost :  0.077667087 Weight : 0.25392646 Bias :  0.7464789\n",
      "Epoch : 0900 Cost :  0.077596374 Weight : 0.2525491 Bias :  0.75663126\n",
      "Epoch : 0950 Cost :  0.077547498 Weight : 0.25140694 Bias :  0.76504976\n",
      "Epoch : 1000 Cost :  0.077513695 Weight : 0.25045964 Bias :  0.7720323\n",
      "Optimization Finished\n",
      "Training cost= 0.077513695 W= 0.25045964 b= 0.7720323 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    '''\n",
    "    learning_rate = 0.03\n",
    "training_epochs = 1000\n",
    "display_step = 50 '''\n",
    "    #print(\"W=\", W.numpy(), \"b=\", b.numpy())\n",
    "    print (\"Learning Rate: \", learning_rate)\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x,y) in zip(train_X,train_Y):\n",
    "           sess.run(optimizer, feed_dict={X:x, Y:y})\n",
    "            \n",
    "        if(epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost,feed_dict = {X: train_X, Y: train_Y})\n",
    "            print (\"Epoch :\", '%04d' %(epoch+1), \"Cost : \", \"{:.9f}\".format(c), \\\n",
    "                  \"Weight :\", sess.run(W), \"Bias : \", sess.run(b))\n",
    "            \n",
    "    print (\"Optimization Finished\")\n",
    "   # tc = sess.run(cost,feed_dict = {X: train_X, Y: train_Y}\n",
    "    #print(\"Training Cost :\" , tc , \"Weight :%d\" % W, \"Bias :%d\" % b)\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "    \n",
    "    #plt.plot(train_X,train_Y, 'r*',label=\"Original\")\n",
    "    plt.plot(train_X,sess.run(W) * train_X + sess.run(b),'r*', label = \"Fitted Line\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphics Display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
